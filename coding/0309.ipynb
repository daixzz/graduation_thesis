{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# å…¶ä¸­çš„éƒ¨åˆ†æ•°æ®\n",
    "filename = 'data1/4th138.json'\n",
    "data = open(filename, encoding='utf-8')\n",
    "strJson1 = json.load(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\"\n",
    "        \"Referer\": \"https://weibo.com\"\n",
    "    }\n",
    "    cookies = {\n",
    "        'cookie':'SINAGLOBAL=4954692280506.27.1591184066784; UOR=,,www.baidu.com; SCF=Au_QDngCAtZdjo2U3MOWDe9AqNjD2bv9bCKkhre3FM48FGdJz4rKLJEWX6ecNp7q5Tg7oJ6FfSgy02zp5_XMbKg.; ULV=1646568933516:68:1:1:5347983324126.591.1646568933470:1644499064874; SUB=_2A25PLLcYDeRhGeVO6VQV8irKyzmIHXVsW6_QrDV8PUNbmtANLRHBkW9NTWqL0HM9wbgK-_eNB3WwaFemzOLZknK_; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WFd.fwHbnebHoYw4M0SwxAm5JpX5KzhUgL.Foe7eoqXeoBceh-2dJLoI7__UgSQIs8DMJxRwntt; ALF=1678375623; SSOLoginState=1646839624'\n",
    "        #'cookie':'SINAGLOBAL=4954692280506.27.1591184066784; UOR=,,www.baidu.com; ULV=1640670361949:63:14:1:8632450552135.697.1640670361940:1639835996800; SCF=Au_QDngCAtZdjo2U3MOWDe9AqNjD2bv9bCKkhre3FM48Gh6mDFxMCacqDmefa19z_7fYJ9W_ldjCbGt1vKO7CaI.; SUB=_2A25Mz7rVDeRhGeVO6VQV8irKyzmIHXVvvKsdrDV8PUJbmtAKLRn-kW9NTWqL0FkKERyR5ZWAAhKgqSgGF5QPtnkp; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WFd.fwHbnebHoYw4M0SwxAm5JpX5K-hUgL.Foe7eoqXeoBceh-2dJLoI7__UgSQIs8DMJxRwntt; ALF=1672280760; SSOLoginState=1640745605; XSRF-TOKEN=8rdPjDQ-y5jyz0mWRw5ZLY24'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, cookies=cookies)\n",
    "    time.sleep(3)   # åŠ ä¸Š5s çš„å»¶æ—¶é˜²æ­¢è¢«åçˆ¬\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"ok\":0,\"msg\":\"\\\\u8fd9\\\\u91cc\\\\u8fd8\\\\u6ca1\\\\u6709\\\\u5185\\\\u5bb9\",\"data\":{\"cards\":[]}}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "header = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "        }\n",
    "uid = '1226258061'\n",
    "page = 0\n",
    "url='https://m.weibo.cn/api/container/getIndex?uid={}&t=0&luicode=10000011&lfid=100103type%3D1%26q%3D%E5%9B%9B%E5%B7%9D%E6%97%A5%E6%8A%A5&type=uid&value={}&containerid=107603{}&page={}'.format(uid,uid,uid,page)\n",
    "URL = 'https://m.weibo.cn/api/container/getIndex?uid=3026424605&luicode=10000011&lfid=231093_-_selffollowed&type=uid&value=1222425514&containerid=1076031222425514'\n",
    "html = requests.get(url = URL, headers = header)\n",
    "html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çˆ¬å–å¾®åšID\n",
      "çˆ¬å–å¤±è´¥\n",
      "çˆ¬å–å¤±è´¥\n",
      "çˆ¬å–å¤±è´¥\n",
      "çˆ¬å–å¤±è´¥\n",
      "çˆ¬å–å¤±è´¥\n",
      "[]\n",
      "æ¯æ¡å¾®åšçš„textçˆ¬å–ï¼š\n",
      "çˆ¬å–å¾®åšä¸ªæ•°ï¼š0\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5a2538494a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmakeWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-5a2538494a3f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclearText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmakeWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5a2538494a3f>\u001b[0m in \u001b[0;36mmakeWordCloud\u001b[0;34m(TEXT)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mcut_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#jiebaåˆ†è¯ï¼Œç©ºæ ¼å­—ç¬¦åˆ†éš”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     wordcloud = WordCloud(\n\u001b[0m\u001b[1;32m     79\u001b[0m        \u001b[0;31m#è®¾ç½®å­—ä½“ï¼Œä¸ç„¶ä¼šå‡ºç°å£å­—ä¹±ç ï¼Œæ–‡å­—çš„è·¯å¾„æ˜¯ç”µè„‘çš„å­—ä½“ä¸€èˆ¬è·¯å¾„ï¼Œå¯ä»¥æ¢æˆåˆ«çš„\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m        \u001b[0mfont_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C:/Windows/Fonts/simfang.ttf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \"\"\"\n\u001b[1;32m    613\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n\u001b[0m\u001b[1;32m    404\u001b[0m                              \"got %d.\" % len(frequencies))\n\u001b[1;32m    405\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt  #ç»˜åˆ¶å›¾åƒçš„æ¨¡å—\n",
    "import  jieba                    #jiebaåˆ†è¯\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #è§£å†³ä¸­æ–‡ä¹±ç \n",
    "\n",
    "'''\n",
    "~æ€»æ€è·¯ï¼šï¼ˆæ‰¾æ¥å£æ˜¯çœŸçš„éº»çƒ¦ï¼‰\n",
    "0.ç½‘é¡µç‰ˆå¾®åšæ‰¾äº†åŠå¤©æ²¡æ‰¾åˆ°æ¥å£ï¼Œåœ¨ç§»åŠ¨ç«¯å¯ä»¥æ‰¾åˆ°ï¼Œç§»åŠ¨ç«¯å¾®åšï¼šhttps://m.weibo.cn/\n",
    "1.Chromeæµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ä¸‹æ‰¾åˆ°getIndex?ç½‘å€ã€‚\n",
    "2.å…ˆçˆ¬å–å¾®åšIDå­˜å…¥åˆ—è¡¨ã€‚\n",
    "3.ç„¶åæ‰¾åˆ°æ¯ä¸ªIDç›¸å¯¹åº”çš„å¾®åšurlï¼Œçˆ¬å–å¾®åšå†…å®¹å’Œå‘å¸ƒæ—¶é—´ã€‚\n",
    "4.æ¸…ç†æ•°æ®ï¼Œåªå‰©ä¸‹ä¸­æ–‡ã€‚\n",
    "5.åˆ©ç”¨jiebaåˆ†è¯ã€‚\n",
    "6.ç”»å‡ºè¯äº‘ã€‚\n",
    "'''\n",
    "'''\n",
    "å‡½æ•°è¯´æ˜ï¼š\n",
    "getID():çˆ¬å–å¾®åšID\n",
    "getText():çˆ¬å–å¾®åšçš„æ–‡æœ¬å³å‘è¡¨æ—¶é—´\n",
    "clearText():æ¸…ç†æ–‡æœ¬ï¼Œåªä¿ç•™ä¸­æ–‡\n",
    "makeWordCloud():åˆ†è¯ï¼Œç»˜å›¾\n",
    "'''\n",
    "def getID(ID):\n",
    "    print(\"çˆ¬å–å¾®åšID\")\n",
    "#    ID = []\n",
    "    for p in range(0,5): #è‡ªå·±è®¾ç½®é¡µæ•°\n",
    "        #ç»è¿‡å°è¯•ï¼Œåœ¨ç½‘å€åé¢åŠ â€œ&page=â€å¯ä»¥ç¿»é¡µ\n",
    "        URL = \"https://m.weibo.cn/api/container/getIndex?uid=3026424605&luicode=10000011&lfid=231093_-_selffollowed&type=uid&value=1222425514&containerid=1076031222425514\"+\"&page=\"+str(p)\n",
    "        try:    \n",
    "            r = requests.get(url = URL, headers = header)        \n",
    "            r.raise_for_status()\n",
    "            r.encoding = r.apparent_encoding\n",
    "            IDD = re.findall('\"id\":\"(.*?)\"',r.text) #åŒ¹é…idï¼ŒIDDä¸ºå½“å‰é¡µé¢çš„æ‰€æœ‰id\n",
    "            ID += IDD #å°†å½“å‰é¡µé¢çš„idåŠ å…¥åˆ°æ€»IDåˆ—è¡¨\n",
    "            print('çˆ¬å–åˆ°çš„idä¸º'+ ID)\n",
    "        except:\n",
    "            print(\"çˆ¬å–å¤±è´¥\")   \n",
    "    print(ID)\n",
    "    return ID\n",
    "\n",
    "def getText(ID, text):\n",
    "    print(\"æ¯æ¡å¾®åšçš„textçˆ¬å–ï¼š\")\n",
    "    text = []\n",
    "    textsingle = []\n",
    "    for i in range(len(ID)):\n",
    "        print(\"ID:\"+ID[i])\n",
    "        #urlååŠ å¾®åšIDå¯æŸ¥çœ‹æ­¤å¾®åšçš„ä¿¡æ¯ï¼Œå…¶ä¸­textä¸ºæ–‡æœ¬ï¼Œcreated_atä¸ºå‘è¡¨æ—¶é—´\n",
    "        url = \"https://m.weibo.cn/detail/\"+ID[i]\n",
    "        print(url)\n",
    "        try:    \n",
    "            r = requests.get(url = url, headers = header)        \n",
    "            r.raise_for_status()\n",
    "            r.encoding = r.apparent_encoding\n",
    "            createTime = re.findall('\"created_at\": \"(.*?)\"',r.text) #åŒ¹é…å‘è¡¨æ—¶é—´\n",
    "            print(\"create at:\"+createTime[0])\n",
    "            print(\"~ ~ ~ ~ ~ ~ ~\")\n",
    "            textsingle = re.findall('\"text\": \"(.*?)\"',r.text) #åŒ¹é…æ­¤å¾®åšæ–‡æœ¬\n",
    "            text += textsingle #å°†æ­¤å¾®åšæ–‡æœ¬åŠ å…¥æ€»å¾®åšæ–‡æœ¬åˆ—è¡¨\n",
    "        except:\n",
    "            print(\"çˆ¬å–å¤±è´¥\")\n",
    "    TEXT = ''\n",
    "    for i in range(len(text)):\n",
    "        TEXT = TEXT + text[i] #å°†åˆ—è¡¨è½¬æ¢æˆå­—ç¬¦å‹TEXTï¼Œä¾¿äºåˆ†è¯\n",
    "    print(\"çˆ¬å–å¾®åšä¸ªæ•°ï¼š\"+str(len(ID)))\n",
    "    return TEXT\n",
    "\n",
    "def clearText(TEXT):\n",
    "    rule = re.compile(u\"[^\\u4e00-\\u9fa5]\") #åŒ¹é…éä¸­æ–‡å­—ç¬¦\n",
    "    TEXT = rule.sub('',TEXT) #å°†éä¸­æ–‡å­—ç¬¦æ›¿æ¢ä¸ºç©º\n",
    "    return TEXT\n",
    "\n",
    "def makeWordCloud(TEXT):    \n",
    "    cut_text = \" \".join(jieba.cut(TEXT)) #jiebaåˆ†è¯ï¼Œç©ºæ ¼å­—ç¬¦åˆ†éš”\n",
    "    print(cut_text)\n",
    "    wordcloud = WordCloud(\n",
    "       #è®¾ç½®å­—ä½“ï¼Œä¸ç„¶ä¼šå‡ºç°å£å­—ä¹±ç ï¼Œæ–‡å­—çš„è·¯å¾„æ˜¯ç”µè„‘çš„å­—ä½“ä¸€èˆ¬è·¯å¾„ï¼Œå¯ä»¥æ¢æˆåˆ«çš„\n",
    "       font_path=\"C:/Windows/Fonts/simfang.ttf\",\n",
    "       #è®¾ç½®äº†èƒŒæ™¯ï¼Œå®½é«˜\n",
    "       background_color=\"white\",width=1000,height=880).generate(cut_text)\n",
    "    \n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    header = {\n",
    "        'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "        }\n",
    "    ID = []\n",
    "    text = []\n",
    "    ID = getID(ID)\n",
    "    text = getText(ID,text)\n",
    "    text = clearText(text)\n",
    "    makeWordCloud(text)\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'm.weibo.cn'\n",
    "base_url = 'https://%s/api/container/getIndex?' % host\n",
    "user_agent = 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1 wechatdevtools/0.7.0 MicroMessenger/6.3.9 Language/zh_CN webview/0'#è¿™é‡Œçš„user_agentæ˜¯ç½‘ä¸Šæ‰¾çš„\n",
    "\n",
    "user_id = str(3026424605)#è¿™ä¸²æ•°å­—å°±æ˜¯ç”¨æˆ·id\n",
    "headers = {\n",
    "    'Host': host,\n",
    "    'Referer': 'https://m.weibo.cn/u/%s'%user_id,\n",
    "    'User-Agent': user_agent\n",
    "}\n",
    "import datetime\n",
    "def timestr_standard(time_str):\n",
    "    now_time = datetime.datetime.now()\n",
    "    if time_str.endswith('åˆ†é’Ÿå‰') or time_str.endswith('å°æ—¶å‰') or time_str == 'åˆšåˆš':\n",
    "        #strptimeæ˜¯æŠŠå­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´ç±»ã€‚strftimeæ˜¯æŠŠæ—¶é—´è½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "        time_standard = datetime.datetime.strftime(now_time.date(),'%Y-%m-%d')\n",
    "    elif time_str.startswith('æ˜¨å¤©'):\n",
    "        time_standard = datetime.datetime.strftime((now_time - datetime.timedelta(days = 1)).date(),'%Y-%m-%d')\n",
    "    elif time_str.startswith('0') or time_str.startswith('1'):\n",
    "        time_standard = str(now_time.year) + '-' + time_str\n",
    "    elif time_str.startswith('20'):\n",
    "        time_standard = time_str\n",
    "    return time_standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import os\n",
    "#import time_standard as tst\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode\n",
    "from pyquery import PyQuery as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_page(page):\n",
    "    params = {\n",
    "        'type': 'uid',\n",
    "        'value': 1665372775,\n",
    "        'containerid': int('107603' + user_id),#containeridå°±æ˜¯å¾®åšç”¨æˆ·idå‰é¢åŠ ä¸Š107603\n",
    "        'page': page\n",
    "    }\n",
    "    url = base_url + urlencode(params)\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "    except requests.ConnectionError as e:\n",
    "        print('æŠ“å–é”™è¯¯', e.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£æé¡µé¢è¿”å›çš„jsonæ•°æ®\n",
    "def analysis_page(json):#ä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„\n",
    "    items = json.get('data').get('cards')\n",
    "    for item in items:\n",
    "        item = item.get('mblog')\n",
    "        if item:\n",
    "            data = {\n",
    "                #'created_at': item.get('created_at'),#å¾®åšåˆ›å»ºæ—¥æœŸ\n",
    "                'text': pq(item.get(\"text\")).text(),  # ä»…æå–å†…å®¹ä¸­çš„æ–‡æœ¬\n",
    "                #'attitudes': item.get('attitudes_count'),#ç‚¹èµæ•°\n",
    "                #'comments': item.get('comments_count'),#è¯„è®ºæ•°\n",
    "                #'reposts': item.get('reposts_count')#è½¬å‘æ•°\n",
    "            }\n",
    "            base_data[len(base_data)] = data#æŠŠå¾—åˆ°çš„æ•°æ®å­—å…¸å­˜å…¥æ€»å­—å…¸\n",
    "#             if pic_choice == 'y':#å¦‚æœé€‰æ‹©ä¿å­˜å›¾ç‰‡\n",
    "#                 pics = item.get('pics')\n",
    "#                 if pics:\n",
    "#                     for pic in pics:\n",
    "#                         picture_url = pic.get('large').get('url')#å¾—åˆ°åŸå›¾åœ°å€\n",
    "#                         pid = pic.get('pid')#å›¾ç‰‡id\n",
    "#                         pic_name = tst.timestr_standard(data['created_at']) + '_' + pid[25:]#æ„å»ºä¿å­˜å›¾ç‰‡æ–‡ä»¶åï¼Œtimestr_standardæ˜¯ä¸€ä¸ªæŠŠå¾®åšçš„created_atå­—ç¬¦ä¸²è½¬æ¢ä¸ºâ€˜XXXX-XX-XXâ€™å½¢å¼æ—¥æœŸçš„ä¸€ä¸ªå‡½æ•°\n",
    "#                         download_pics(picture_url,pic_name,pic_filebagPath)#ä¸‹è½½åŸå›¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " totally cost -1932.026831150055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    base_data = {}\n",
    "    #page = input('è¯·è¾“å…¥ä½ è¦çˆ¬å–çš„é¡µæ•°')#å¯è¾“å…¥çˆ¬å–é¡µæ•°ï¼Œæˆ–è€…è¾“å…¥â€˜allâ€™çˆ¬å–æ‰€æœ‰å¾®åš\n",
    "    page = 5\n",
    "    #pic_choice = input('æ˜¯å¦éœ€è¦å­˜å‚¨å›¾ç‰‡?y/n')#é€‰æ‹©æ˜¯å¦ä¿å­˜å›¾ç‰‡\n",
    "    pic_choice = 'n'\n",
    "    time_start=time.time()\n",
    "    try:\n",
    "        json = get_single_page(1)\n",
    "        screen_name = json.get('data').get('cards')[0].get('mblog').get('user').get('screen_name')#åšä¸»æ˜µç§°\n",
    "        total = json.get('data').get('cardlistInfo').get('total')#åšä¸»å¾®åšæ€»æ¡æ•°\n",
    "#         if pic_choice == 'y':#å¦‚æœé€‰æ‹©ä¿å­˜å›¾ç‰‡ï¼Œåˆ™åˆ†é…å›¾ç‰‡ä¿å­˜è·¯å¾„\n",
    "#             pic_filebagPath = 'D:\\\\python_project\\\\crawl\\\\weibo\\\\%s_picture'%screen_name\n",
    "#             os.makedirs(pic_filebagPath)#å»ºç«‹æ–‡ä»¶å¤¹\n",
    "#         else:\n",
    "#             pic_filebagPath = None#é€‰æ‹©ä¸ä¿å­˜æ–‡ä»¶å¤¹åˆ™ä¸åˆ†é…è·¯å¾„\n",
    "#         if page == 'all':#å¯»æ‰¾æ€»æ¡æ•°\n",
    "#             page = total//10\n",
    "#             while get_single_page(page).get('ok') == 1:\n",
    "#                 page = page + 1\n",
    "#             print('æ€»é¡µæ•°ä¸ºï¼š%s'%page)\n",
    "        page = int(page) + 1\n",
    "        for page in tqdm(range(1,page)):  # æŠ“å–æ•°æ®\n",
    "            json = get_single_page(page)\n",
    "            analysis_page(json)\n",
    "    except Exception as e:\n",
    "        print('error:',e)\n",
    "    finally:\n",
    "        #base_dataPath = 'D:\\\\python_project\\\\crawl\\\\weibo\\\\base_data_%s.txt'%screen_name#base_dataä¿å­˜åœ°å€å’Œæ–‡ä»¶å\n",
    "        #f = open(base_dataPath,'w+',encoding='utf-8')\n",
    "        #f.write(str(base_data))\n",
    "        #f.close()\n",
    "        #time_end=time.time()\n",
    "        print('\\n totally cost',time_end-time_start)#æ˜¾ç¤ºç¨‹åºè¿è¡Œæ—¶é—´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'text': 'æç«¯åˆ†å­å‡ºæ²¡ æŸ¥çœ‹å›¾ç‰‡'},\n",
       " 1: {'text': 'è¯¡è®¡å¤šç«¯çš„å¤–ä¼ ä¸‰å…«å°±ä½ ä¸æ”¾å‡ ç¤¼ç‰©æ˜¯å°å…æ´—æ´—æ‰‹æ¶²ï½'},\n",
       " 2: {'text': 'æ¯•ä¸šè®ºæ–‡ æˆ‘çœŸçš„äº¤ä¸å‡ºæ¥ æ•‘æ•‘å¶'},\n",
       " 3: {'text': 'Repost'},\n",
       " 4: {'text': 'å¦‚æœæˆ‘æœ‰é’±äº†â€¦'},\n",
       " 5: {'text': 'ä»Šå¤©ä¸€å¤©éƒ½ä¼šå¿ƒç¢å¤å¥'},\n",
       " 6: {'text': 'Repost'},\n",
       " 7: {'text': 'æ”¯æŒ'},\n",
       " 8: {'text': 'è°å‘€ æ–°å¹´ç¬¬ä¸€å¤© ç‹ ç‹ çš„eäº†'},\n",
       " 9: {'text': 'æˆ‘è§‰å¾—å·®ä¸å¤šäº† å¤§æ¦‚å°±æ˜¯ä»¥å‰è§‰å¾—æ‰˜ç¦è¿‡äº†greå·®ä¸å¤šäº†å°±æ˜¯ç¨³ç¨³çš„å¹¸ç¦ ä½†æ˜¯ç°åœ¨å®¡è§†æ•´ä¸ªç”³è¯·è¿‡ç¨‹ çœŸæ­£æ‹–åè…¿çš„å…¶å®æ˜¯æœ¬ç§‘é™¢æ ¡å’Œgpa ç°åœ¨é¢‡æœ‰å°‘å£®ä¸åŠªåŠ›è€å¤§å¾’ä¼¤æ‚²çš„æ„Ÿè§‰'},\n",
       " 10: {'text': 'åŸæ¥åœ¨æ°´é€†mdmdmdmdmd'},\n",
       " 11: {'text': 'å·¦æ€å³æƒ³è¿˜æ˜¯è§‰å¾—ä»Šå¹´è¿™ä¸ªå¹´å¼€å¾—æœ‰é—®é¢˜'},\n",
       " 12: {'text': '5555å¦‚æœæŸä¸ªå­¦æ ¡ä¸èƒ½updateæ‰˜ç¦æˆç»© é‚£æˆ‘ä¸€æœˆä»½è€ƒä»–çš„æ„ä¹‰åœ¨å“ª'},\n",
       " 13: {'text': 'æƒ³åˆ°è¿˜æœ‰å‡ ä¸ªå­¦æ ¡çš„æ¨èä¿¡é“¾æ¥æ²¡æœ‰å‘ç»™è€å¸ˆ æˆ‘ä¸€æ•´ä¸ªå°±æ˜¯ä¸æƒ³ç”³è¯·äº†'},\n",
       " 14: {'text': '20å²ç¦»å¼€å¾—å¤ªå¿« å¯¹2021å¹´çš„è®°å¿†å±…ç„¶åªå‰©ä¸‹äº†æœ€åå‡ ä¸ªæœˆä¸åœè€ƒè¯•çš„å´©æºƒ21å²ç”Ÿæ´»\\n2021æ²¡æœ‰é‚£ä¹ˆç³Ÿç³•å°¼'},\n",
       " 15: {'text': '@ets å‡ºä¸‹æˆ‘ä»Šå¹´çš„å¹´åº¦æŠ¥å‘Š'},\n",
       " 16: {'text': 'æ±‚æ±‚'},\n",
       " 17: {'text': 'è½¬å‘å¾®åš'},\n",
       " 18: {'text': 'ok'},\n",
       " 19: {'text': 'çƒçƒäº†//@ä¹‹ä¹‹ç„¡èª:ğŸ™ğŸ™ğŸ™'},\n",
       " 20: {'text': 'çƒçƒ//@muchhairdxz:æˆ‘ä¸ä¿è¯äº†//@muchhairdxz:ä¿¡å¥³æ„¿ä¸¤ä¸ªæœˆä¸è¯´è„è¯//@muchhairdxz:ğŸ™ ä¿¡å¥³æ„¿ä¸€ä¸ªæœˆä¸éª‚è„è¯'},\n",
       " 21: {'text': 'è½¬å‘å¾®åš'},\n",
       " 22: {'text': 'æˆ‘é‡æ–°æ‹¼100æ¬¡offer å¼¥è¡¥æˆ‘çš„é”™è¯¯ å¯¹ä¸èµ·offerä¹‹ç¥'},\n",
       " 23: {'text': 'æˆ‘æ˜¯ä¸­å›½äºº æˆ‘ä¸åšåˆ†æ•°çš„å¥´éš¶'},\n",
       " 24: {'text': 'è°¢è°¢ä½ '},\n",
       " 25: {'text': 'æˆ‘ä¸ä¿è¯äº†//@muchhairdxz:ä¿¡å¥³æ„¿ä¸¤ä¸ªæœˆä¸è¯´è„è¯//@muchhairdxz:ğŸ™ ä¿¡å¥³æ„¿ä¸€ä¸ªæœˆä¸éª‚è„è¯'},\n",
       " 26: {'text': 'ç¬‘æ­»//@å½“ä»£æ–°é”ç”·å¤§å­¦ç”Ÿ:leecodeï¼ŒåŒ—ç¾äºšç”·çš„äº”ä¸‰ //@ä¸è¦å†ä¸ºéš¾æˆ‘å•¦:å»äº†ç¾å›½æ²¡æ··å¥½ï¼Œå½’å› äºå»çš„æ˜¯ä¸œå²¸NYä¸æ˜¯è¥¿å²¸LAï¼Œå»äº†è¥¿å²¸æ²¡æ··å¥½ï¼Œå½’å› äºleetcodeé¢˜åˆ·å°‘äº†'},\n",
       " 27: {'text': 'æˆä¸æˆçš„æ²‰æ²¡æˆæœ¬éƒ½æ‘†åœ¨é‚£äº† æ— æ‰€è°“äº†'},\n",
       " 28: {'text': 'ç”ŸåŠ¨å½¢è±¡çš„æè¿°äº†æˆ‘æœ¬äºº'},\n",
       " 29: {'text': 'åˆ«äººéƒ½åœ¨æ”¶offer å®šå¥½è¦å»å“ªäº† è€Œæˆ‘åˆ°ç°åœ¨åªé€’äº¤äº†ä¸€ä¸ªç”³è¯· è¿˜æ˜¯é‚£ç§ä¸è¦ps ä¸è¦æ¨èä¿¡çš„ æ„æ€å°±æ˜¯ps cv rlæˆ‘éƒ½è¿˜æ²¡æ•´å®Œ'},\n",
       " 30: {'text': 'yes'},\n",
       " 31: {'text': 'ä¿¡å¥³æ„¿ä¸¤ä¸ªæœˆä¸è¯´è„è¯//@muchhairdxz:ğŸ™ ä¿¡å¥³æ„¿ä¸€ä¸ªæœˆä¸éª‚è„è¯'},\n",
       " 32: {'text': 'è°ä¸æƒ³ç¾ç¾èººå¹³'},\n",
       " 33: {'text': 'æœ€å¥½æ˜¯'},\n",
       " 34: {'text': 'ğŸ™ ä¿¡å¥³æ„¿ä¸€ä¸ªæœˆä¸éª‚è„è¯'},\n",
       " 35: {'text': 'yesok'},\n",
       " 36: {'text': 'è°¢è°¢ä½ å¥¥'},\n",
       " 37: {'text': 'è«æ‹‰å¤ï¼Ÿï¼Ÿè®°è€…ä½ ä½†å‡¡æå‰æŠ¥é“ä¸¤å¤©'},\n",
       " 38: {'text': 'æ˜¯çœŸçš„'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
